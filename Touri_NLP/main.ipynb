{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwhisper\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyaudio\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import whisper\n",
    "import pyaudio\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUDIO RECORDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "filename = \"recorded.wav\"\n",
    "chunk = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "channels = 1\n",
    "sample_rate = 44100\n",
    "record_seconds = 10\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=channels,\n",
    "                rate=sample_rate,\n",
    "                input=True,\n",
    "                output=True,\n",
    "                frames_per_buffer=chunk)\n",
    "frames = []\n",
    "print(\"Recording...\")\n",
    "for i in range(int(sample_rate / chunk * record_seconds)):\n",
    "    data = stream.read(chunk, exception_on_overflow = False)\n",
    "    frames.append(data)\n",
    "print(\"Finished recording.\")\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "wf = wave.open(filename, \"wb\")\n",
    "wf.setnchannels(channels)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(sample_rate)\n",
    "wf.writeframes(b\"\".join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSLATE AND TRANCRIBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = dict(language='en', best_of=1)\n",
    "transcribe_options = dict(task=\"transcribe\", **options)\n",
    "translate_options = dict(task=\"translate\", **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prakhar/opt/miniconda3/envs/ML/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey, Dory. Hey, Dory. Hey, Dory.\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(\"recorded.wav\", **translate_options)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.organization = \"org-zRTzRjJAC89L2HyHHIGG4vGH\"\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectList = {\n",
    "    0 : 'object_0 - white color bottle with a red cap with \"CMU\" labels\\n',\n",
    "    1 : 'object_1 - black tennis ball\\n',\n",
    "    4 : 'object_4 - green monkey stuffed toy keychain\\n',\n",
    "    6 : 'object_6 - black color dog belt\\n',\n",
    "    7 : 'object_7 - set of three white table tennis balls\\n',\n",
    "    8 : 'object_8 - white cow stuffed toy keychain\\n',\n",
    "    10 : 'object_10 - stuffed unicorn toy which is white in color\\n',\n",
    "    11 : 'object_11 - airpods case to keep airpods safe\\n',\n",
    "}\n",
    "\n",
    "exampleList = {\n",
    "    #BOTTLE\n",
    "    0 : [\n",
    "        'Command: Pick up that white bottle\\nSelected object: object_0\\n\\n',\n",
    "        'Command: Pick up the bottle\\nSelected object: object_0\\n\\n',\n",
    "    ],\n",
    "    #TENNIS BALL\n",
    "    1 : [\n",
    "        'Command: Pick up the black ball\\nSelected object: object_1\\n\\n',\n",
    "        'Command: I want that tennis ball\\nSelected object: object_1\\n\\n',\n",
    "    ],\n",
    "    #MONKEY KEYCHAIN\n",
    "    4 : [\n",
    "        'Command: Buy that monkey keychain\\nSelected object: object_4\\n\\n',\n",
    "        'Command: I want that monkey\\nSelected object: object_4\\n\\n',\n",
    "    ],\n",
    "    #DOG BELT\n",
    "    6 : [\n",
    "        'Command: Pick up a gift for my dog\\nSelected object: object_6\\n\\n',\n",
    "        'Command: Buy the dog belt\\nSelected object: object_6\\n\\n',\n",
    "    ],\n",
    "    #TABLE TENNIS BALLS\n",
    "    7 : [\n",
    "        'Command: Pick up those ping pong balls\\nSelected object: object_7\\n\\n',\n",
    "        'Command: Buy the table tennis balls\\nSelected object: object_7\\n\\n',\n",
    "    ],\n",
    "    #COW_KEYCHAIN\n",
    "    8 : [\n",
    "        'Command: Buy the cow keychain\\nSelected object: object_8\\n\\n',\n",
    "        'Command: I want the that cow\\nSelected object: object_8\\n\\n',\n",
    "    ],\n",
    "    #UNICORN\n",
    "    10 : [\n",
    "        'Command: Pick up the unicorn\\nSelected object: object_10\\n\\n',\n",
    "        'Command: I want to buy that unicorn keychain\\nSelected object: object_10\\n\\n',\n",
    "    ], \n",
    "    #AIRPODS CASE\n",
    "    11 : [\n",
    "        'Command: I want a new airpod case\\nSelected object: object_11\\n\\n',\n",
    "        'Command: Could you buy me that airpods case\\nSelected object: object_11\\n\\n',\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPrompt(command, detectionList):\n",
    "\n",
    "    prompt = 'The following objects are available\\n\\n'\n",
    "\n",
    "    for objNum in detectionList:\n",
    "        prompt += objectList[objNum]\n",
    "\n",
    "    prompt += '\\n'\n",
    "\n",
    "    for objNum in detectionList:\n",
    "        for j in exampleList[objNum]:\n",
    "            prompt += j\n",
    "\n",
    "\n",
    "\n",
    "    prompt += 'Command: {}\\nSelected object:'''.format(command)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectIdDict = {\n",
    "    'object_0' : 'cmu_tartan_bottle', #BOTTLE\n",
    "    'object_1' : 'tennis_ball_toy', #TENNIS BALL\n",
    "    'object_4' : 'monkey_keychain', #MONKEY KEYCHAIN\n",
    "    'object_6' : 'all_star_dog_belt', #DOG BELT\n",
    "    'object_7' : 'table_tennis_balls', #TABLE TENNIS BALLS \n",
    "    'object_8' : 'cow_keychain', #COW KEYCHAIN\n",
    "    'object_10' : 'unicorn', #UNICORN\n",
    "    'object_11' : 'airpods_case', #AIRPODS CASE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def think(command):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=createPrompt(command, [0, 1, 4, 8]), #BOTTLE, TENNIS BALL, MONKEY KEYCHAIN, COW KEYCHAIN\n",
    "        max_tokens=3,\n",
    "        temperature=0,\n",
    "        best_of=3\n",
    "        )\n",
    "\n",
    "    print(response['choices'][0]['text'].strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object_8\n"
     ]
    }
   ],
   "source": [
    "think(\"Pick up that white toy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<firebase_admin.App at 0x148144d90>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred = credentials.Certificate(\"/Users/prakhar/Development/Playground/MachineLearningPlayground/Touri_NLP/keys/touri-65f07-firebase-adminsdk-wuv71-b245c875f8.json\")\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': 'https://touri-65f07-default-rtdb.firebaseio.com/',\n",
    "    'storageBucket' : 'touri-65f07.appspot.com' \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDetectionList():\n",
    "    detectionList =  db.reference(\"autoSkills/nlp/detections\").get()\n",
    "    return detectionList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '   this is a test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08433e0cffb6b31896868c9fb611d1bed4e943d8fd5463e533a0eb267f0d0c65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
